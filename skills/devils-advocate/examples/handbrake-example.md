# Example: Full Protocol Stack â€” Data Pipeline Migration

> **Original proposal (from Data Engineer):** Migrate our user events pipeline from batch (daily Spark job â†’ Redshift) to real-time streaming (Kafka + Flink â†’ Redshift). Estimated timeline: 6 weeks. The pipeline processes 500M events/day including click events, purchases, and session data. PII fields: email, IP address, user_id.

---

## âš¡ IMMEDIATE REPORT â€” ğŸ”´ Critical Finding

**Finding**: PII fields (email, IP, user_id) will flow through Kafka topics and Flink state with no documented masking, access control, or GDPR erasure strategy.
**Domain**: Data
**Why immediate**: Irreversible + Compliance â€” once PII lands in Kafka topic logs (default 7-day retention), erasure under GDPR Art. 17 is impossible without topic deletion.
**Risk if not addressed**: GDPR violation. Erasure requests cannot be fulfilled. Regulatory fine up to 4% of global annual revenue. Kafka logs may be accessible to engineers without business need.

---
### ğŸ” Context Needed

1. **PII scope**: Which exact fields in each event type are personally identifiable? Is user_id considered PII in your jurisdiction?
2. **Erasure capability**: Today, how do you fulfill a GDPR "right to be forgotten" request on the batch pipeline? Is there a process?
3. **Access control**: Who has read access to the Kafka topics and the Flink state store today in the proposed design?
4. **Data residency**: Are any EU users' events included? Where will Kafka brokers be hosted?
5. **Retention**: What is the planned Kafka topic retention period?

---
Reply: ğŸ“ [answers] to raise confidence | `continue` to proceed at worst-case score

*(Context received from Data Engineer: "email and IP are PII. user_id is pseudonymous but considered PII under GDPR by our DPO. Erasure today: we DELETE rows in Redshift. Kafka: all engineers can read all topics â€” no ACLs yet. EU users included. Kafka in US-East. Retention: 7 days planned. No GDPR review done on this design.")*

---

## ğŸ›‘ HANDBRAKE ACTIVATED

**Critical finding**: PII in Kafka without erasure strategy, ACLs, or legal basis for cross-border transfer
**Domain**: Data + Legal/Compliance
**Why Handbrake level**: Multi-domain Critical (Data + Legal). GDPR Art. 17 erasure is architecturally impossible once PII lands in immutable Kafka log. Cross-border transfer to US-East without SCCs is an additional violation.
**Responsible roles**: **Data Engineer / Analytics Engineer** + **Legal / Compliance team**

---
**Analysis is paused.** Input needed from both specialists:

**From the Data Engineer:**
1. Is pseudonymization at the source (replace email/IP with a tokenized ID before Kafka ingestion) technically feasible in this pipeline?
2. Can the token-to-PII mapping be stored only in a separate, erasable store (not in Kafka)?
3. What is the impact on downstream ML/analytics if email and IP are replaced with tokens?

**From Legal / Compliance:**
1. Is there a Data Processing Agreement (DPA) covering Kafka and Flink as data processors?
2. Are Standard Contractual Clauses (SCCs) in place for US-East data transfer of EU user data?
3. Does the current DPO-approved retention policy permit 7-day Kafka retention for raw PII?

---
*(Context received: "Pseudonymization is feasible â€” we can tokenize at ingest. Token store in Postgres with delete capability. Email/IP not needed by ML â€” only user_id token needed. Legal: no DPA for Kafka yet. SCCs not in place. DPO says 7-day raw PII retention is not approved â€” max 24h or pseudonymize.")*

**Re-analysis**: PII risk is reducible to ğŸŸ  High (not eliminated) with pseudonymization + Postgres token store. Legal/cross-border issues are new independent ğŸ”´ Critical findings that must be resolved before any EU data flows through the new pipeline.

---

# ğŸ”´ Devil's Advocate Analysis: Real-Time Event Pipeline Migration

**Analyzed**: 2026-02-20
**Skill version**: 2.8.0
**Scope**: Data â€” batch Spark/Redshift to Kafka + Flink + Redshift, 500M events/day, PII-containing

---

## ğŸ“Š Executive Summary

**Overall Risk Rating**: ğŸ”´ Critical

**Key Findings**:
1. PII in Kafka without erasure strategy violates GDPR Art. 17 (unresolvable without re-architecture)
2. No SCCs or DPA for EUâ†’US cross-border data transfer â€” independent legal violation
3. No pipeline idempotency â€” Flink failure causes duplicate event counts and double-attributed purchases

**Recommendation**: âš ï¸ Needs fixes â€” proceed only after pseudonymization architecture is implemented and Legal resolves DPA/SCCs. Estimated additional 3â€“4 weeks before first EU data can flow.

**Analysis Confidence**: ğŸŸ¢ High â€” both Data Engineer and Legal provided full context

---

## ğŸ›‘ Handbrake & âš¡ Immediate Report Status

| Protocol | Finding | Domain | Escalated to | Context received | Risk change |
|----------|---------|--------|-------------|-----------------|-------------|
| âš¡ Immediate | PII in Kafka without erasure | Data | Data Engineer | âœ… Full â€” pseudonymization feasible | ğŸ”½ Critical â†’ High (with mitigation path) |
| ğŸ›‘ Handbrake | GDPR erasure + cross-border transfer | Data + Legal | Data Eng + Legal | âœ… Full â€” SCCs absent, DPA missing | ğŸ”º Raised: new Legal Critical surfaced |

**Re-analysis note**: Pseudonymization resolves the erasure architectural impossibility. However, Legal review surfaced two independent violations (no DPA for Kafka, no SCCs for EUâ†’US) that must be resolved before EU data can enter the pipeline. Non-EU data can proceed after pseudonymization is implemented.

---

## âœ… Strengths (What Works Well)

1. **Event-driven architecture** â€” correct direction for 500M events/day; batch will not scale beyond current volumes
2. **Database-per-consumer pattern** â€” each consumer (Redshift) owns its own read model; no shared mutable state
3. **Team identified the migration proactively** â€” addressing scale limits before they become incidents

---

## âŒ Weaknesses (What Could Fail)

### ğŸ”´ Critical Issues (Must fix before production)

1. **No GDPR erasure strategy for Kafka** *(Handbrake â€” mitigation path: pseudonymization)*
   - **Risk**: Raw PII in immutable Kafka log; erasure requests cannot be fulfilled
   - **Impact**: GDPR Art. 17 violation; fine up to 4% annual global revenue
   - **Likelihood**: High â€” EU users are in the dataset
   - **Mitigation**: Tokenize PII at source before Kafka ingestion; store tokenâ†”PII map in Postgres with hard-delete capability

2. **No DPA or SCCs for EUâ†’US data transfer** *(Handbrake â€” Legal resolution required)*
   - **Risk**: EU user data transferred to US-East Kafka without Standard Contractual Clauses
   - **Impact**: GDPR Chapter V violation; independent from the erasure issue
   - **Likelihood**: Certain â€” EU users confirmed in dataset, brokers in US-East
   - **Mitigation**: Legal to execute SCCs and DPA with Kafka/Flink processors before first EU event flows

3. **No pipeline idempotency**
   - **Risk**: Flink checkpoint failure or Kafka at-least-once delivery causes duplicate events processed
   - **Impact**: Purchase events double-counted; revenue metrics and ML training data corrupted
   - **Likelihood**: Medium â€” Flink failures are common in first 90 days of operation
   - **Mitigation**: Implement event deduplication key (event_id + user_id + timestamp); use upsert into Redshift

### ğŸŸ  High-Priority Issues

1. **No Kafka ACLs â€” all engineers can read all topics**
   - **Risk**: Engineers without business need can read PII-containing topics
   - **Impact**: Data breach surface via insider access; compliance audit failure
   - **Mitigation**: Implement Kafka ACLs before first event flows; topic-level read permissions per team

2. **No consumer lag monitoring**
   - **Risk**: Flink falls behind; pipeline processes hours-old events silently; dashboards show stale data
   - **Mitigation**: Kafka consumer lag alert at < 5-minute lag threshold with PagerDuty integration

3. **No schema registry**
   - **Risk**: Producer changes event schema; Flink consumer fails on new fields or missing fields silently
   - **Mitigation**: Confluent Schema Registry with backward-compatibility enforcement before first deploy

4. **7-day raw PII retention not DPO-approved**
   - **Risk**: DPO-approved max is 24h for raw PII; 7-day plan is non-compliant
   - **Mitigation**: Reduce topic retention to 24h for PII topics; unlimited retention allowed for pseudonymized topics

### ğŸŸ¡ Medium-Priority Issues

1. **No dead letter queue defined** â€” malformed events will cause Flink to crash-loop or silently drop
2. **No backfill strategy** â€” if pipeline falls behind, no documented process to replay historical events without reprocessing all 500M
3. **Redshift COPY not idempotent** â€” current plan uses COPY command which will duplicate rows on retry

---

## âš ï¸ Assumptions Challenged

| Assumption | Challenge | Evidence | Risk if wrong |
|---|---|---|---|
| Kafka is GDPR-compliant as designed | PII in immutable log; erasure impossible | âŒ Confirmed by Legal | GDPR violation on first EU event |
| 6-week timeline is achievable | Pseudonymization + ACLs + SCCs add 3â€“4 weeks | âŒ Not in original scope | Timeline doubles; stakeholders not informed |
| Flink processes each event exactly once | At-least-once delivery by default | âŒ Idempotency not designed | Revenue metrics corrupted |
| email/IP not needed by downstream ML | Confirmed by Data Engineer | âœ… Verified | Token-only is feasible |

---

## ğŸ¯ Edge Cases & Failure Modes

| Scenario | What Happens | Handled? | Risk | Fix |
|----------|-------------|----------|------|-----|
| GDPR erasure request received | Cannot delete from Kafka log | âŒ No | Critical | Pseudonymize at source |
| Flink restarts from checkpoint | Events since last checkpoint reprocessed | âŒ No dedup | Critical | Idempotent upsert + dedup key |
| EU user data flows before SCCs signed | GDPR Chapter V violation | âŒ No | Critical | Gate EU data until Legal completes |
| Schema change pushed to producer | Flink consumer crashes or silently drops | âŒ No | High | Schema Registry + compatibility check |
| Consumer lag > 30 minutes | Dashboard shows stale data, no alert | âŒ No | High | Lag monitor + alert |
| Dead letter queue fills up | Events dropped silently | âŒ No | Medium | DLQ monitor + alert |

---

## ğŸ”’ Security Concerns

### STRIDE Summary
- **Spoofing**: Kafka producer authentication not mentioned â€” any internal service could publish to event topics âš ï¸
- **Tampering**: Events in transit not encrypted (TLS not confirmed) âš ï¸
- **Repudiation**: No event-level audit trail for who produced which event âš ï¸
- **Information Disclosure**: All engineers can read PII-containing topics (no ACLs) âŒ
- **Denial of Service**: No rate limiting on Kafka producers â€” one misbehaving service can flood topics âš ï¸
- **Elevation of Privilege**: Flink service account permissions not scoped â€” may have broader access than needed âš ï¸

---

## âš¡ Performance Concerns

- **Bottleneck**: Redshift COPY from Flink sink â€” Redshift has limited concurrent write throughput; at 500M events/day this is ~5,800 events/sec sustained
- **Scalability limit**: Flink parallelism not specified â€” if under-provisioned, consumer lag will grow under peak traffic
- **Resource usage**: Flink state store for deduplication will grow proportionally to event volume; sizing not defined

---

## ğŸ’¡ Alternative Solutions

1. **Pseudonymize at source (recommended mitigation)**
   - Better at: GDPR compliance, Kafka erasure, unlimited retention on pseudonymized topics
   - Worse at: Requires token store operational overhead
   - Consider if: Email/IP not needed downstream (confirmed by Data Engineer)

2. **Keep batch for EU users, stream for non-EU**
   - Better at: EU compliance without re-architecture
   - Worse at: Two pipelines to maintain; technical debt
   - Consider if: Legal timeline for SCCs is > 8 weeks

---

## âœ… Recommendations

### Must Do (Before first EU event flows)
- [ ] Implement pseudonymization at Kafka ingest (Data Engineer â€” 1 week)
- [ ] Execute DPA and SCCs with Kafka/Flink processors (Legal â€” 2â€“3 weeks)
- [ ] Implement Kafka ACLs scoped per topic and team (Data Engineer â€” 3 days)

### Must Do (Before any production traffic)
- [ ] Implement event deduplication with idempotent upsert into Redshift
- [ ] Deploy Schema Registry with backward-compatibility enforcement
- [ ] Define dead letter queue + monitoring alert

### Should Do (Next sprint)
- [ ] Consumer lag alert (< 5 min threshold â†’ PagerDuty)
- [ ] Reduce PII topic retention to 24h (DPO requirement)
- [ ] Define Flink parallelism and state store sizing for 500M events/day

### Consider (Backlog)
- [ ] Backfill/replay runbook for consumer lag recovery
- [ ] mTLS between Kafka producers and brokers

---

## ğŸ“‹ Follow-Up Questions

1. What is Legal's estimated timeline for executing SCCs and DPA with Confluent/Flink?
2. Is user_id the only identifier needed by ML models, or are behavioral sequences (session-level) also needed?
3. What is the maximum acceptable consumer lag before dashboards show stale-data warnings to users?

---
ğŸ”´ Devil's Advocate complete.

**Before I proceed, please confirm:**
- [ ] I have reviewed all Critical and High issues above
- [ ] I accept the risks marked as accepted (or they are mitigated)
- [ ] I want to proceed with the approved action

Reply with:
  âœ… Proceed   â€” continue with the approved action as planned
  ğŸ” Revise    â€” describe the change and I will re-analyse
  âŒ Cancel    â€” stop, do not implement
  `continue`   â€” proceed without addressing remaining issues (risks remain active and unmitigated)
